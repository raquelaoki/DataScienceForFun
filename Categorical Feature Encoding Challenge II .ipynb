{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport pandas as pd\nimport numpy as np\n#from sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/cat-in-the-dat-ii/sample_submission.csv\n/kaggle/input/cat-in-the-dat-ii/test.csv\n/kaggle/input/cat-in-the-dat-ii/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def auc(y_true, y_pred):\n    def fallback_auc(y_true, y_pred):\n        try:\n            return metrics.roc_auc_score(y_true, y_pred)\n        except:\n            return 0.5\n    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)\n","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\")#.sample(n=30000, random_state=1)\ntest = pd.read_csv(\"../input/cat-in-the-dat-ii/test.csv\")#.sample(n=1000, random_state=1)\nsample = pd.read_csv(\"../input/cat-in-the-dat-ii/sample_submission.csv\")\n\ndf_train = train \ndf_test = test\nprint(train.shape, test.shape)\n","execution_count":3,"outputs":[{"output_type":"stream","text":"(30000, 25) (1000, 24)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(df_test.head())\ndf_test = pd.DataFrame(df_test)\ndf_test = df_test.fillna(df_test.mean())\ndf_test = df_test.fillna('Empty999')\n#print(df_test.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transforming all features together \ndf_test[\"target\"] = -1\ndata = pd.concat([df_train, df_test]).reset_index(drop=True)\nprint(data.shape ,df_train.shape, df_test.shape)\ndata.dropna(inplace = True)\nprint(data.shape ,df_train.shape, df_test.shape)\nfeatures = [x for x in df_train.columns if x not in [\"id\", \"target\"]]\n\nfor feat in features:\n    lbl_enc = preprocessing.LabelEncoder()\n    data[feat] = lbl_enc.fit_transform(data[feat].fillna(\"-1\").astype(str).values)\n    ","execution_count":4,"outputs":[{"output_type":"stream","text":"(31000, 25) (30000, 25) (1000, 25)\n(15265, 25) (30000, 25) (1000, 25)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exploration: eliminate categorial variables with many classes (for now, might add them back later)\n#print(data.head())\n#for feat in features:\n    #print(feat, data[feat].value_counts().shape)\n\n#eliminate nom_5, nom_6, nom_9    \ndid = data['id'].values\ndtarget = data['target'].values\ndata.drop(['nom_5','nom_6','nom_9','id','target'],axis=1,inplace=True)\n\n\n#Estimate number of columns\nfor feat in data.columns:\n    count = data[feat].value_counts().shape\n    #print(feat, count)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlb = preprocessing.OneHotEncoder(handle_unknown='ignore')\ndata_new = mlb.fit_transform(data.astype(str))\nprint(data_new.shape)\nprint(data.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(15265, 742)\n(15265, 20)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = pd.DataFrame(data_new.toarray())\ndata_new['id'] = did\ndata_new['target'] = dtarget\nprint(data_new.shape)","execution_count":7,"outputs":[{"output_type":"stream","text":"(15265, 744)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data_new[data_new.target != -1].reset_index(drop=True)\ntest = data_new[data_new.target == -1].reset_index(drop=True)\n\nprint(train.shape,test.shape, data_new.shape)\n","execution_count":8,"outputs":[{"output_type":"stream","text":"(14785, 744) (480, 744) (15265, 744)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb = 30000 #(30k)\ntrain1 = data_new[data_new.target == 1].reset_index(drop=True)\ntrain0 = data_new[data_new.target == 0].reset_index(drop=True)\ntrain1 = train1.sample(n=nb, random_state=5)\ntrain0 = train0.sample(n=nb, random_state=6)\ntrain = pd.concat([train1, train0]).reset_index(drop=True)\ntrain = train.sample(frac=1).reset_index(drop=True)\n\ntest = data_new[data_new.target == -1].reset_index(drop=True)\n#test = test.sample(n=int(test.shape[0]*0.1), random_state=1)\n#test_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]\n\nprint('First time consuming fitting',train.shape, test.shape)\ny = np.array(train.target)\nX = train.drop(['target','id'], axis  = 1)\nX_ = test.drop(['target','id'], axis  = 1)\nX = X.to_numpy()\nX_ = X_.to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","execution_count":11,"outputs":[{"output_type":"stream","text":"First time consuming fitting (5000, 744) (480, 744)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import GridSearchCV\n#from sklearn.model_selection import StratifiedShuffleSplit\n#from sklearn.svm import SVC\n\n\n#param_grid = [\n#  {'C': [0.1, 0.2, 0.4, 0.5, 1, 1.5,10], 'kernel': ['linear']},\n#  {'C': [0.1, 0.2, 0.4, 0.5, 1, 1.5,10], 'gamma':[0.0001, 0.001, 0.01,0.05,0.08,0.1, 0.15, 0.5, 1], 'kernel': ['rbf']},\n#]\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n#cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n\n#grid = GridSearchCV(SVC(class_weight={1: 5}), param_grid=param_grid, cv=cv)\n#grid.fit(X_train, y_train)\n\n#print(\"The best parameters are %s with a score of %0.2f\"\n#      % (grid.best_params_, grid.best_score_))\n#grid.cv_results_.keys()#['mean_test_score']     \n#grid.cv_results_['mean_test_score']   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1: 0.67860 (V8) (only 100000 samples)\nmodel1 = False\nif model1: \n    clf = svm.SVC(kernel='rbf',gamma=0.1,C=0.3)\n    clf.fit(X_train, y_train)\n    y_val = clf.predict(X_test)\n    y_train_val = clf.predict(X_train)\n    test_preds =  clf.predict(X_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 2: 0.66 (V11)\nmodel2 = False\nif model2: \n    from sklearn.ensemble import RandomForestClassifier\n    rf = RandomForestClassifier(n_estimators=500, max_depth=30, class_weight={1: 5}, random_state = 42)\n    rf.fit(X_train, y_train)\n    y_val = rf.predict(X_test)\n    y_train_val = rf.predict(X_train)\n    test_preds =  rf.predict(X_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 3: 0.62027 (v15)\nmodel3 = False\nif model3 and model2:\n    fi = pd.DataFrame({'col':np.arange(0,len(rf.feature_importances_)), 'fi': rf.feature_importances_})\n    fi.sort_values(by=['fi'], inplace=True,ascending=False)\n    fi = fi.iloc[0:20,:]\n\n    train = data_new[data_new.target != -1].reset_index(drop=True)\n    train = train.sample(n=int(train.shape[0]*0.8), random_state=10)\n    test = data_new[data_new.target == -1].reset_index(drop=True)\n    #test_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]\n    print(train.shape)\n    y = np.array(train.target)\n    X = train.drop(['target','id'], axis  = 1)\n    X_ = test.drop(['target','id'], axis  = 1)\n    X = X[fi.col]\n    X_ = X_[fi.col]\n\n    X = X.to_numpy()\n    X_ = X_.to_numpy()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    print(X_train.shape)\n    clf = svm.SVC(kernel='rbf',gamma=0.1,C=0.3, class_weight={1: 5})\n    clf.fit(X_train, y_train)\n    y_val = clf.predict(X_test)\n    y_train_val = clf.predict(X_train)\n    test_preds =  clf.predict(X_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model 4: NN\nmodel4 = True\n\nif model4: \n    import tensorflow as tf\n    from tensorflow import keras\n\n    model = keras.Sequential([\n        keras.layers.Flatten(input_shape=(X_train.shape[1],)),\n        keras.layers.Dense(16, activation=tf.nn.relu),\n        keras.layers.Dense(16, activation=tf.nn.relu),\n        keras.layers.Dense(1, activation=tf.nn.sigmoid),\n    ])\n    #model = keras.Sequential([\n    #keras.layers.Flatten(input_shape=(28, 28)),\n    #keras.layers.Dense(128, activation='relu'),\n    #keras.layers.Dense(10)\n    #])\n    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\n    model.fit(X_train, y_train, epochs=50, batch_size=1)\n    #test_loss, test_acc = model.evaluate(X_test, y_test)\n    y_val = model.predict(X_test)\n    y_train_val = model.predict(X_train)\n    test_preds =  model.predict(X_)\n","execution_count":12,"outputs":[{"output_type":"stream","text":"Train on 3350 samples\nEpoch 1/50\n3350/3350 [==============================] - 6s 2ms/sample - loss: 0.6346 - accuracy: 0.6496\nEpoch 2/50\n3350/3350 [==============================] - 6s 2ms/sample - loss: 0.5480 - accuracy: 0.7266\nEpoch 3/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.5013 - accuracy: 0.7537\nEpoch 4/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.4403 - accuracy: 0.7925\nEpoch 5/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.3722 - accuracy: 0.8349\nEpoch 6/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.3023 - accuracy: 0.8722\nEpoch 7/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.2248 - accuracy: 0.9116\nEpoch 8/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.1637 - accuracy: 0.9409\nEpoch 9/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.1100 - accuracy: 0.9654\nEpoch 10/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0744 - accuracy: 0.9758\nEpoch 11/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0468 - accuracy: 0.9881\nEpoch 12/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0284 - accuracy: 0.9916\nEpoch 13/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0172 - accuracy: 0.9955\nEpoch 14/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0157 - accuracy: 0.9955\nEpoch 15/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0054 - accuracy: 0.9991\nEpoch 16/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0018 - accuracy: 1.0000\nEpoch 17/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0064 - accuracy: 0.9973\nEpoch 18/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0046 - accuracy: 0.9982\nEpoch 19/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0045 - accuracy: 0.9991\nEpoch 20/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0035 - accuracy: 0.9994\nEpoch 21/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 4.0793e-04 - accuracy: 1.0000\nEpoch 22/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 3.0539e-04 - accuracy: 1.0000\nEpoch 23/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 6.5955e-04 - accuracy: 1.0000\nEpoch 24/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 3.4120e-04 - accuracy: 1.0000\nEpoch 25/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 1.2926e-04 - accuracy: 1.0000\nEpoch 26/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0052 - accuracy: 0.9985\nEpoch 27/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 7.7830e-04 - accuracy: 0.9994\nEpoch 28/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0028 - accuracy: 0.9985\nEpoch 29/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 6.1830e-04 - accuracy: 0.9997\nEpoch 30/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 3.9917e-05 - accuracy: 1.0000\nEpoch 31/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 2.2083e-06 - accuracy: 1.0000\nEpoch 32/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 9.7454e-07 - accuracy: 1.0000\nEpoch 33/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 5.5329e-07 - accuracy: 1.0000\nEpoch 34/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0019 - accuracy: 0.9997\nEpoch 35/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0011 - accuracy: 0.9994\nEpoch 36/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 9.4975e-05 - accuracy: 1.0000\nEpoch 37/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 4.6226e-06 - accuracy: 1.0000\nEpoch 38/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 5.3334e-07 - accuracy: 1.0000\nEpoch 39/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 2.5081e-07 - accuracy: 1.0000\nEpoch 40/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 6.2100e-08 - accuracy: 1.0000\nEpoch 41/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 2.3135e-08 - accuracy: 1.0000\nEpoch 42/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 1.1802e-06 - accuracy: 1.0000\nEpoch 43/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0024 - accuracy: 0.9994\nEpoch 44/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 0.0023 - accuracy: 0.9994\nEpoch 45/50\n3350/3350 [==============================] - 6s 2ms/sample - loss: 2.7224e-06 - accuracy: 1.0000\nEpoch 46/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 4.6371e-08 - accuracy: 1.0000\nEpoch 47/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 2.5259e-08 - accuracy: 1.0000\nEpoch 48/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 1.9568e-08 - accuracy: 1.0000\nEpoch 49/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 1.1452e-08 - accuracy: 1.0000\nEpoch 50/50\n3350/3350 [==============================] - 5s 2ms/sample - loss: 5.8269e-09 - accuracy: 1.0000\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'clf' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-75043ba05722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#test_loss, test_acc = model.evaluate(X_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0my_train_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf = svm.SVC(kernel='rbf',gamma=0.1,C=0.3, class_weight={1: 5})\n#clf.fit(X_train, y_train)\n#y_val = clf.predict(X_test)\n#y_train_val = clf.predict(X_train)\n#test_preds =  clf.predict(X_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_train,y_train_val.astype(int)))\nprint(confusion_matrix(y_test,y_val.astype(int)))\nprint(\"Overall AUC={}\".format(metrics.roc_auc_score(y_test, y_val.astype(int))))","execution_count":20,"outputs":[{"output_type":"stream","text":"[[1664    0]\n [   7 1679]]\n[[684 152]\n [515 299]]\nOverall AUC=0.5927518427518427\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_preds /= 50\ntest_ids = test.id.values\nprint(\"Saving submission file\")\nsubmission = pd.DataFrame.from_dict({\n    'id': test_ids,\n    'target': test_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}